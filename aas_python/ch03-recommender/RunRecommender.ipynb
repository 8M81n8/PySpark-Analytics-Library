{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.conf\n",
    "import pyspark.sql\n",
    "SparkConf = pyspark.conf.SparkConf\n",
    "SparkSession = pyspark.sql.SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "            .appName(\"Intro\") \\\n",
    "            .config('spark.executor.memory', '2g') \\\n",
    "            .config('spark.driver.memory','8g') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/home/ubuntu/profiledata_06-May-2005/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = datadir\n",
    "rawUserArtistData = spark.read.text(base + \"user_artist_data.txt\")\n",
    "rawArtistData = spark.read.text(base + \"artist_data.txt\")\n",
    "rawArtistAlias = spark.read.text(base + \"artist_alias.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        runRecommender = RunRecommender(spark)\n",
    "        runRecommender.preparation(rawUserArtistData, rawArtistData, rawArtistAlias)\n",
    "        runRecommender.model(rawUserArtistData, rawArtistData, rawArtistAlias)\n",
    "        runRecommender.evaluate(rawUserArtistData, rawArtistAlias)\n",
    "        runRecommender.recommend(rawUserArtistData, rawArtistData, rawArtistAlias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(value='1000002 1 55')\n",
      "Row(value='1000002 1000006 33')\n",
      "Row(value='1000002 1000007 8')\n",
      "Row(value='1000002 1000009 144')\n",
      "Row(value='1000002 1000010 314')\n"
     ]
    }
   ],
   "source": [
    "for _ in rawUserArtistData.take(5):\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(row):\n",
    "    cols = row.value.split(' ')\n",
    "    user, artist = cols[:2]\n",
    "    return int(user), int(artist)\n",
    "# end def\n",
    "    \n",
    "userArtistDF = rawUserArtistData.rdd.map(fx).toDF([\"user\", \"artist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+-----------+\n",
      "|min(user)|max(user)|min(artist)|max(artist)|\n",
      "+---------+---------+-----------+-----------+\n",
      "|       90|  2443548|          1|   10794401|\n",
      "+---------+---------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userArtistDF.agg(F.min(\"user\"), F.max(\"user\"), F.min(\"artist\"), F.max(\"artist\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildArtistByID(rawArtistData):\n",
    "    def func(row):\n",
    "        try:\n",
    "            (_id, name) = row.value.split('\\t')\n",
    "        except ValueError:\n",
    "            return None, None\n",
    "        # end try\n",
    "        if (name.strip() == ''):\n",
    "            return None, None\n",
    "        else:\n",
    "            try:\n",
    "                return int(_id), name.strip()\n",
    "            except:\n",
    "                return None, None\n",
    "            # end try\n",
    "        # end if\n",
    "    # end def\n",
    "    return rawArtistData.rdd.map(func).toDF([\"id\", \"name\"]).na.drop()\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistByID = buildArtistByID(rawArtistData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildArtistAlias(rawArtistAlias):\n",
    "    def func(row):\n",
    "        try:\n",
    "            artist, alias = row.value.split('\\t')\n",
    "        except ValueError:\n",
    "            return None, None\n",
    "        # end try\n",
    "        if (artist.strip()==''):\n",
    "            return None, None\n",
    "        else:\n",
    "            return int(artist), int(alias)\n",
    "        # end if\n",
    "    # end def\n",
    "    return dict(rawArtistAlias.rdd.map(func).collect())\n",
    "# end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistAlias = buildArtistAlias(rawArtistAlias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "(badID, goodID) = next(iter(artistAlias.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|     id|              name|\n",
      "+-------+------------------+\n",
      "|1109457|             P.O.S|\n",
      "|2097152|DJ Tiesto -  P.O.S|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artistByID.filter(F.col('id').isin([badID, goodID])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bArtistAlias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-fb92faaf6562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbArtistAlias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bArtistAlias' is not defined"
     ]
    }
   ],
   "source": [
    "bArtistAlias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "bArtistAlias = spark.sparkContext.broadcast(buildArtistAlias(rawArtistAlias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildCounts(rawUserArtistData, bArtistAlias):\n",
    "    def func(row):\n",
    "        try:\n",
    "            userID, artistID, count = map(int, row.value.split(' '))\n",
    "            finalArtistID = bArtistAlias.value.get(artistID, artistID)\n",
    "            return (userID, finalArtistID, count)\n",
    "        except ValueError:\n",
    "            return None, None, None\n",
    "        # end try\n",
    "    # end def\n",
    "    return rawUserArtistData.rdd.map(func).toDF([\"user\", \"artist\", \"count\"]).na.drop()\n",
    "# end def\n",
    "trainData = buildCounts(rawUserArtistData, bArtistAlias).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36389746970260883"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-ed24c568dc16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msetSeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msetImplicitPrefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msetRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msetRegParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Random' is not defined"
     ]
    }
   ],
   "source": [
    "model = ALS().\\\n",
    "    setSeed(Random.nextLong()).\\\n",
    "    setImplicitPrefs(true).\\\n",
    "    setRank(10).\\\n",
    "    setRegParam(0.01).\\\n",
    "    setAlpha(1.0).\\\n",
    "    setMaxIter(5).\\\n",
    "    setUserCol(\"user\").\\\n",
    "    setItemCol(\"artist\").\\\n",
    "    setRatingCol(\"count\").\\\n",
    "    setPredictionCol(\"prediction\").\\\n",
    "    fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def model(rawUserArtistData, rawArtistData, rawArtistAlias):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        trainData.unpersist()\n",
    "\n",
    "        model.userFactors.select(\"features\").show(truncate = false)\n",
    "\n",
    "        userID = 2093760\n",
    "\n",
    "        existingArtistIDs = trainData.\n",
    "            filter($\"user\" === userID).\n",
    "            select(\"artist\").as[Int].collect()\n",
    "\n",
    "        artistByID = buildArtistByID(rawArtistData)\n",
    "\n",
    "        artistByID.filter($\"id\" isin (existingArtistIDs:_*)).show()\n",
    "\n",
    "        topRecommendations = makeRecommendations(model, userID, 5)\n",
    "        topRecommendations.show()\n",
    "\n",
    "        recommendedArtistIDs = topRecommendations.select(\"artist\").as[Int].collect()\n",
    "\n",
    "        artistByID.filter($\"id\" isin (recommendedArtistIDs:_*)).show()\n",
    "\n",
    "        model.userFactors.unpersist()\n",
    "        model.itemFactors.unpersist()\n",
    "    # end def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def evaluate(\n",
    "            rawUserArtistData,\n",
    "            rawArtistAlias):\n",
    "\n",
    "        bArtistAlias = self.spark.sparkContext.broadcast(buildArtistAlias(rawArtistAlias))\n",
    "\n",
    "        allData = buildCounts(rawUserArtistData, bArtistAlias)\n",
    "        Array(trainData, cvData) = allData.randomSplit(Array(0.9, 0.1))\n",
    "        trainData.cache()\n",
    "        cvData.cache()\n",
    "\n",
    "        allArtistIDs = allData.select(\"artist\").as[Int].distinct().collect()\n",
    "        bAllArtistIDs = self.spark.sparkContext.broadcast(allArtistIDs)\n",
    "\n",
    "        mostListenedAUC = areaUnderCurve(cvData, bAllArtistIDs, predictMostListened(trainData))\n",
    "        print(mostListenedAUC)\n",
    "\n",
    "        evaluations =\n",
    "            for (rank         <- Seq(5,    30);\n",
    "                     regParam <- Seq(1.0, 0.0001);\n",
    "                     alpha        <- Seq(1.0, 40.0))\n",
    "            yield {\n",
    "                model = ALS().\n",
    "                    setSeed(Random.nextLong()).\n",
    "                    setImplicitPrefs(true).\n",
    "                    setRank(rank).setRegParam(regParam).\n",
    "                    setAlpha(alpha).setMaxIter(20).\n",
    "                    setUserCol(\"user\").setItemCol(\"artist\").\n",
    "                    setRatingCol(\"count\").setPredictionCol(\"prediction\").\n",
    "                    fit(trainData)\n",
    "\n",
    "                auc = areaUnderCurve(cvData, bAllArtistIDs, model.transform)\n",
    "\n",
    "                model.userFactors.unpersist()\n",
    "                model.itemFactors.unpersist()\n",
    "\n",
    "                (auc, (rank, regParam, alpha))\n",
    "            # end def\n",
    "\n",
    "        evaluations.sorted.reverse.foreach(print)\n",
    "\n",
    "        trainData.unpersist()\n",
    "        cvData.unpersist()\n",
    "    # end def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    def recommend(\n",
    "            rawUserArtistData,\n",
    "            rawArtistData,\n",
    "            rawArtistAlias):\n",
    "\n",
    "        bArtistAlias = self.spark.sparkContext.broadcast(buildArtistAlias(rawArtistAlias))\n",
    "        allData = buildCounts(rawUserArtistData, bArtistAlias).cache()\n",
    "        model = ALS().\n",
    "            setSeed(Random.nextLong()).\n",
    "            setImplicitPrefs(true).\n",
    "            setRank(10).setRegParam(1.0).setAlpha(40.0).setMaxIter(20).\n",
    "            setUserCol(\"user\").setItemCol(\"artist\").\n",
    "            setRatingCol(\"count\").setPredictionCol(\"prediction\").\n",
    "            fit(allData)\n",
    "        allData.unpersist()\n",
    "\n",
    "        userID = 2093760\n",
    "        topRecommendations = makeRecommendations(model, userID, 5)\n",
    "\n",
    "        recommendedArtistIDs = topRecommendations.select(\"artist\").as[Int].collect()\n",
    "        artistByID = buildArtistByID(rawArtistData)\n",
    "        artistByID.join(self.spark.createDataset(recommendedArtistIDs).toDF(\"id\"), \"id\").\n",
    "            select(\"name\").show()\n",
    "\n",
    "        model.userFactors.unpersist()\n",
    "        model.itemFactors.unpersist()\n",
    "    # end def\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def makeRecommendations(model: ALSModel, userID, howMany):\n",
    "        toRecommend = model.itemFactors.\n",
    "            select($\"id\".as(\"artist\")).\n",
    "            withColumn(\"user\", lit(userID))\n",
    "        model.transform(toRecommend).\n",
    "            select(\"artist\", \"prediction\").\n",
    "            orderBy($\"prediction\".desc).\n",
    "            limit(howMany)\n",
    "    # end def\n",
    "\n",
    "    def areaUnderCurve(\n",
    "            positiveData,\n",
    "            bAllArtistIDs: Broadcast[Array[Int]],\n",
    "            predictFunction: (DataFrame : DataFrame)):\n",
    "\n",
    "        # What this actually computes is AUC, per user. The result is actually something\n",
    "        # that might be called \"mean AUC\".\n",
    "\n",
    "        # Take held-out data as the \"positive\".\n",
    "        # Make predictions for each of them, including a numeric score\n",
    "        positivePredictions = predictFunction(positiveData.select(\"user\", \"artist\")).\n",
    "            withColumnRenamed(\"prediction\", \"positivePrediction\")\n",
    "\n",
    "        # BinaryClassificationMetrics.areaUnderROC is not used here since there are really lots of\n",
    "        # small AUC problems, and it would be inefficient, when a direct computation is available.\n",
    "\n",
    "        # Create a set of \"negative\" products for each user. These are randomly chosen\n",
    "        # from among all of the other artists, excluding those that are \"positive\" for the user.\n",
    "        negativeData = positiveData.select(\"user\", \"artist\").as[(Int,Int)].\n",
    "            groupByKey { case (user, _) : user # end def.\n",
    "            flatMapGroups { case (userID, userIDAndPosArtistIDs) :\n",
    "                random = Random()\n",
    "                posItemIDSet = userIDAndPosArtistIDs.map { case (_, artist) : artist # end def.toSet\n",
    "                negative = ArrayBuffer[Int]()\n",
    "                allArtistIDs = bAllArtistIDs.value\n",
    "                var i = 0\n",
    "                # Make at most one pass over all artists to avoid an infinite loop.\n",
    "                # Also stop when number of negative equals positive set size\n",
    "                while (i < allArtistIDs.length && negative.size < posItemIDSet.size) {\n",
    "                    artistID = allArtistIDs(random.nextInt(allArtistIDs.length))\n",
    "                    # Only add distinct IDs\n",
    "                    if (!posItemIDSet.contains(artistID)) {\n",
    "                        negative += artistID\n",
    "                    # end def\n",
    "                    i += 1\n",
    "                # end def\n",
    "                # Return the set with user ID added back\n",
    "                negative.map(artistID : (userID, artistID))\n",
    "            # end def.toDF(\"user\", \"artist\")\n",
    "\n",
    "        # Make predictions on the rest:\n",
    "        negativePredictions = predictFunction(negativeData).\n",
    "            withColumnRenamed(\"prediction\", \"negativePrediction\")\n",
    "\n",
    "        # Join positive predictions to negative predictions by user, only.\n",
    "        # This will result in a row for every possible pairing of positive and negative\n",
    "        # predictions within each user.\n",
    "        joinedPredictions = positivePredictions.join(negativePredictions, \"user\").\n",
    "            select(\"user\", \"positivePrediction\", \"negativePrediction\").cache()\n",
    "\n",
    "        # Count the number of pairs per user\n",
    "        allCounts = joinedPredictions.\n",
    "            groupBy(\"user\").agg(count(lit(\"1\")).as(\"total\")).\n",
    "            select(\"user\", \"total\")\n",
    "        # Count the number of correctly ordered pairs per user\n",
    "        correctCounts = joinedPredictions.\n",
    "            filter($\"positivePrediction\" > $\"negativePrediction\").\n",
    "            groupBy(\"user\").agg(count(\"user\").as(\"correct\")).\n",
    "            select(\"user\", \"correct\")\n",
    "\n",
    "        # Combine these, compute their ratio, and average over all users\n",
    "        meanAUC = allCounts.join(correctCounts, Seq(\"user\"), \"left_outer\").\n",
    "            select($\"user\", (coalesce($\"correct\", lit(0)) / $\"total\").as(\"auc\")).\n",
    "            agg(mean(\"auc\")).\n",
    "            as[Double].first()\n",
    "\n",
    "        joinedPredictions.unpersist()\n",
    "\n",
    "        meanAUC\n",
    "    # end def\n",
    "\n",
    "    def predictMostListened(train)(allData):\n",
    "        listenCounts = train.groupBy(\"artist\").\n",
    "            agg(sum(\"count\").as(\"prediction\")).\n",
    "            select(\"artist\", \"prediction\")\n",
    "        allData.\n",
    "            join(listenCounts, Seq(\"artist\"), \"left_outer\").\n",
    "            select(\"user\", \"artist\", \"prediction\")\n",
    "    # end def\n",
    "\n",
    "# end class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
